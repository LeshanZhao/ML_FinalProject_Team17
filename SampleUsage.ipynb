{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlp\n",
    "import matplotlib.pyplot as plt\n",
    "from cross_validation import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Reproducibility\n",
    "# import random\n",
    "# random.seed(6630)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial uses the developer's data as example. <br/>\n",
    "The data_opener component only works for developer's data. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_opener\n",
    "data = data_opener.get_data()\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = data_opener.train_test_val_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user wants to use his own data, he should prepare the data by himself. <br/>\n",
    "(i.e., read from file and format data into the following shape:)  <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age              0.921562\n",
      "height           0.708000\n",
      "weight           0.450000\n",
      "ap_hi            0.009988\n",
      "ap_lo            0.009091\n",
      "smoke            0.000000\n",
      "alco             0.000000\n",
      "active           1.000000\n",
      "cholesterol_2    0.000000\n",
      "cholesterol_3    0.000000\n",
      "gluc_2           0.000000\n",
      "gluc_3           0.000000\n",
      "is_man           1.000000\n",
      "Name: 9289, dtype: float64\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Show the first row of X_train\n",
    "print(X_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Show the first row of y_train\n",
    "print(y_train.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please do data preprocessing before train the model.  <br/>\n",
    "Specifically, please note that:  <br/>\n",
    "\n",
    "1. All the features must be numeric (Could be binary).  <br/>\n",
    "2. For each categorical variables with n classes, please refactor it into (n-1) binary variables.\n",
    "3. Remove highly linear dependent columns or use less columns (such as index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "For demonstration purpose, here we use only the first 200 samples as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 200\n",
    "\n",
    "X_train = X_train.head(n_samples)\n",
    "y_train = y_train.head(n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Decide the hyper-parameters you want to use.</br>\n",
    "    You can skip this step, but you need to specify them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 13\n",
    "lr = .00001\n",
    "n_epochs = 1000\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Call the \"MLP\" class to initilize a MLP classifier. <br/>\n",
    "    The user need to specify the `numer of features` and `sizes of hidden layer`s at this point. <br/>\n",
    "    The user could also specify the `learning rate`, `batch size`, <br/>\n",
    "    number of `epochs`, and whether to `include bias` in his model, <br/>\n",
    "    the value for which by defaut are `25`, `1`, `1` and `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf = mlp.MLP(n_features = n_features, \n",
    "                    hidden_sizes = [8], \n",
    "                    n_epochs = n_epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    include_bias = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Call the `train` method <br/>\n",
    "For the `learning rate`, the user could specify a different value each time he train a new model. (This is also optional.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the training set\n",
    "mlp_clf.train(X_train, y_train, lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the model to `predict` whether a patient is at high risk of haveing cariovascular diseases. <br/>\n",
    "The output from the `predict` method will be float point values from 0 to 1, <br/>\n",
    "where y >= 0.5 indicates that the patient is at high risk of having cardiovascular diseases now or in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Training set\n",
    "y_pred = mlp_clf.pred(X_train)\n",
    "y_pred_train = list(map(lambda x: 1 if x >= 0.5 else 0, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate statistics metrics on training set prediction, i.e., acc, recall, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: ===============\n",
      "Accuracy:\t0.46\n",
      "ErrorRate:\t0.54\n",
      "Precision:\t0.48295454545454547\n",
      "Recall:\t0.8333333333333334\n",
      "\n",
      "Confusion matrix:\n",
      "\t\t\tPositive\tNegative\t\n",
      "pred_pos\t85\t\t\t91\t\n",
      "pred_neg\t17\t\t\t7\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print statistics and confusion matrix for prediction on training set\n",
    "calc_stats = cross_validation()\n",
    "stats_train = calc_stats.print_stat(y_train, y_pred_train)\n",
    "print(\"Training set: ===============\")\n",
    "print(stats_train[0])\n",
    "print(stats_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test set\n",
    "For model selection, use the model to predict your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: ===============\n",
      "Accuracy:\t0.4635714285714286\n",
      "ErrorRate:\t0.5364285714285715\n",
      "Precision:\t0.4824033627297453\n",
      "Recall:\t0.8263447691656078\n",
      "\n",
      "Confusion matrix:\n",
      "\t\t\tPositive\tNegative\t\n",
      "pred_pos\t5853\t\t\t6280\t\n",
      "pred_neg\t1230\t\t\t637\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on Test set\n",
    "y_pred = mlp_clf.pred(X_test)\n",
    "y_pred_test = list(map(lambda x: 1 if x >= 0.5 else 0, y_pred))\n",
    "\n",
    "# print statistics and confusion matrix for prediction on test set\n",
    "# calc_stats = cross_validation()\n",
    "stats_test = calc_stats.print_stat(y_test, y_pred_test)\n",
    "print(\"Test set: ===============\")\n",
    "print(stats_test[0])\n",
    "print(stats_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on validation set\n",
    "Assume that we have found the optimal model using the previous hypermeters, i.e., the current model. <br/>\n",
    "Now, predict on the validation set to get the model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: ===============\n",
      "Accuracy:\t0.46014285714285713\n",
      "ErrorRate:\t0.5398571428571428\n",
      "Precision:\t0.4762996316004912\n",
      "Recall:\t0.8336437885083823\n",
      "\n",
      "Confusion matrix:\n",
      "\t\t\tPositive\tNegative\t\n",
      "pred_pos\t5818\t\t\t6397\t\n",
      "pred_neg\t1161\t\t\t624\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on Validation set\n",
    "y_pred = mlp_clf.pred(X_val)\n",
    "y_pred_val = list(map(lambda x: 1 if x >= 0.5 else 0, y_pred))\n",
    "\n",
    "# print statistics and confusion matrix for prediction on Validation set\n",
    "# calc_stats = cross_validation()\n",
    "stats_val = calc_stats.print_stat(y_val, y_pred_val)\n",
    "print(\"Validation: ===============\")\n",
    "print(stats_val[0])\n",
    "print(stats_val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you say the your model performance is 46% (bad performance in fact. Please find better hyper-parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "To prevent or reduce overfitting, the user may want to do K-fold `cross validation`. <br/>\n",
    "For `tutorial` of how to run cross validation, please refer to \"`cv_main.py`\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23df60a54607d347e031d49868c92248a09c44b3ac715a89ec2cdbd92691ffb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
